{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:35:10.717577Z",
     "start_time": "2020-05-17T15:35:05.260831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import timeit\n",
    "import json\n",
    "import linecache\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm, trange\n",
    "import pytrec_eval\n",
    "import scipy as sp\n",
    "from copy import copy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except:\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "from transformers import WEIGHTS_NAME, BertConfig, BertTokenizer, AlbertConfig, AlbertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from utils import (LazyQuacDatasetGlobal, RawResult, \n",
    "                   write_predictions, write_final_predictions, \n",
    "                   get_retrieval_metrics, gen_reader_features)\n",
    "from retriever_utils import RetrieverDataset\n",
    "from modeling import Pipeline, AlbertForRetrieverOnlyPositivePassage, BertForOrconvqaGlobal\n",
    "from scorer import quac_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:35:10.728245Z",
     "start_time": "2020-05-17T15:35:10.721971Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ALL_MODELS = list(BertConfig.pretrained_config_archive_map.keys())\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'reader': (BertConfig, BertForOrconvqaGlobal, BertTokenizer),\n",
    "    'retriever': (AlbertConfig, AlbertForRetrieverOnlyPositivePassage, AlbertTokenizer),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:35:10.941606Z",
     "start_time": "2020-05-17T15:35:10.731238Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:35:11.250213Z",
     "start_time": "2020-05-17T15:35:10.945181Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(args, train_dataset, model, retriever_tokenizer, reader_tokenizer):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer = SummaryWriter(os.path.join(args.output_dir, 'logs'))\n",
    "\n",
    "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "    train_sampler = RandomSampler(\n",
    "        train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, num_workers=args.num_workers)\n",
    "\n",
    "    if args.max_steps > 0:\n",
    "        t_total = args.max_steps\n",
    "        args.num_train_epochs = args.max_steps // (\n",
    "            len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
    "    else:\n",
    "        t_total = len(\n",
    "            train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(\n",
    "            nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                      lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    args.warmup_steps = int(t_total * args.warmup_portion)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
    "    if args.fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(\n",
    "            model, optimizer, opt_level=args.fp16_opt_level)\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        # model.to(f'cuda:{model.device_ids[0]}')\n",
    "\n",
    "    # Distributed training (should be after apex fp16 initialization)\n",
    "    if args.local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],\n",
    "                                                          output_device=args.local_rank,\n",
    "                                                          find_unused_parameters=True)\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Instantaneous batch size per GPU = %d\",\n",
    "                args.per_gpu_train_batch_size)\n",
    "    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "                args.train_batch_size * args.gradient_accumulation_steps * (torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n",
    "    logger.info(\"  Gradient Accumulation steps = %d\",\n",
    "                args.gradient_accumulation_steps)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 1\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    retriever_tr_loss, retriever_logging_loss = 0.0, 0.0\n",
    "    reader_tr_loss, reader_logging_loss = 0.0, 0.0\n",
    "    qa_tr_loss, qa_logging_loss = 0.0, 0.0\n",
    "    rerank_tr_loss, rerank_logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(args.num_train_epochs),\n",
    "                            desc=\"Epoch\", disable=args.local_rank not in [-1, 0])\n",
    "    # Added here for reproductibility (even between python 2 and 3)\n",
    "    set_seed(args)\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\",\n",
    "                              disable=args.local_rank not in [-1, 0])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.eval() # we first get query representations in eval mode\n",
    "            qids = np.asarray(batch['qid']).reshape(-1).tolist()\n",
    "            # print('qids', qids)\n",
    "            question_texts = np.asarray(\n",
    "                batch['question_text']).reshape(-1).tolist()\n",
    "            # print('question_texts', question_texts)\n",
    "            answer_texts = np.asarray(\n",
    "                batch['answer_text']).reshape(-1).tolist()\n",
    "            # print('answer_texts', answer_texts)\n",
    "            answer_starts = np.asarray(\n",
    "                batch['answer_start']).reshape(-1).tolist()\n",
    "            # print('answer_starts', answer_starts)\n",
    "            query_reps = gen_query_reps(args, model, batch)\n",
    "                \n",
    "            retrieval_results = retrieve(args, qids, qid_to_idx, query_reps,\n",
    "                                         passage_ids, passage_id_to_idx, passage_reps,\n",
    "                                         qrels, qrels_sparse_matrix,\n",
    "                                         gpu_index, include_positive_passage=True)\n",
    "            passage_reps_for_retriever = retrieval_results['passage_reps_for_retriever']\n",
    "            labels_for_retriever = retrieval_results['labels_for_retriever']\n",
    "\n",
    "            pids_for_reader = retrieval_results['pids_for_reader']\n",
    "            # print(pids_for_reader)\n",
    "            passages_for_reader = retrieval_results['passages_for_reader']\n",
    "            labels_for_reader = retrieval_results['labels_for_reader']\n",
    "\n",
    "            model.train()\n",
    "            \n",
    "            inputs = {'query_input_ids': batch['query_input_ids'].to(args.device),\n",
    "                      'query_attention_mask': batch['query_attention_mask'].to(args.device),\n",
    "                      'query_token_type_ids': batch['query_token_type_ids'].to(args.device),\n",
    "                      'passage_rep': torch.from_numpy(passage_reps_for_retriever).to(args.device),\n",
    "                      'retrieval_label': torch.from_numpy(labels_for_retriever).to(args.device)}\n",
    "            retriever_outputs = model.retriever(**inputs)\n",
    "            # model outputs are always tuple in transformers (see doc)\n",
    "            retriever_loss = retriever_outputs[0]\n",
    "\n",
    "            reader_batch = gen_reader_features(qids, question_texts, answer_texts, answer_starts,\n",
    "                                        pids_for_reader, passages_for_reader, labels_for_reader,\n",
    "                                        reader_tokenizer, args.reader_max_seq_length, is_training=True)\n",
    "\n",
    "            reader_batch = {k: v.to(args.device) for k, v in reader_batch.items()}\n",
    "            inputs = {'input_ids':       reader_batch['input_ids'],\n",
    "                      'attention_mask':  reader_batch['input_mask'],\n",
    "                      'token_type_ids':  reader_batch['segment_ids'],\n",
    "                      'start_positions': reader_batch['start_position'],\n",
    "                      'end_positions':   reader_batch['end_position'],\n",
    "                      'retrieval_label': reader_batch['retrieval_label']}\n",
    "            reader_outputs = model.reader(**inputs)\n",
    "            reader_loss, qa_loss, rerank_loss = reader_outputs[0:3]\n",
    "\n",
    "            loss = retriever_loss + reader_loss\n",
    "\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu parallel (not distributed) training\n",
    "                retriever_loss = retriever_loss.mean()\n",
    "                reader_loss = reader_loss.mean()\n",
    "                qa_loss = qa_loss.mean()\n",
    "                rerank_loss = rerank_loss.mean()\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "                retriever_loss = retriever_loss / args.gradient_accumulation_steps\n",
    "                reader_loss = reader_loss / args.gradient_accumulation_steps\n",
    "                qa_loss = qa_loss / args.gradient_accumulation_steps\n",
    "                rerank_loss = rerank_loss / args.gradient_accumulation_steps\n",
    "\n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            retriever_tr_loss += retriever_loss.item()\n",
    "            reader_tr_loss += reader_loss.item()\n",
    "            qa_tr_loss += qa_loss.item()\n",
    "            rerank_tr_loss += rerank_loss.item()\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                if args.fp16:\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        amp.master_params(optimizer), args.max_grad_norm)\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        model.parameters(), args.max_grad_norm)\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                    # Log metrics\n",
    "                    # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                    if args.local_rank == -1 and args.evaluate_during_training:\n",
    "                        results = evaluate(args, model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar(\n",
    "                                'eval_{}'.format(key), value, global_step)\n",
    "                    tb_writer.add_scalar(\n",
    "                        'lr', scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar(\n",
    "                        'loss', (tr_loss - logging_loss)/args.logging_steps, global_step)\n",
    "                    tb_writer.add_scalar(\n",
    "                        'retriever_loss', (retriever_tr_loss - retriever_logging_loss)/args.logging_steps, global_step)\n",
    "                    tb_writer.add_scalar(\n",
    "                        'reader_loss', (reader_tr_loss - reader_logging_loss)/args.logging_steps, global_step)\n",
    "                    tb_writer.add_scalar(\n",
    "                        'qa_loss', (qa_tr_loss - qa_logging_loss)/args.logging_steps, global_step)\n",
    "                    tb_writer.add_scalar(\n",
    "                        'rerank_loss', (rerank_tr_loss - rerank_logging_loss)/args.logging_steps, global_step)\n",
    "                    logging_loss = tr_loss\n",
    "                    retriever_logging_loss = retriever_tr_loss\n",
    "                    reader_logging_loss = reader_tr_loss\n",
    "                    qa_logging_loss = qa_tr_loss\n",
    "                    rerank_logging_loss = rerank_tr_loss\n",
    "\n",
    "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
    "                    # Save model checkpoint\n",
    "                    output_dir = os.path.join(\n",
    "                        args.output_dir, 'checkpoint-{}'.format(global_step))\n",
    "                    retriever_model_dir = os.path.join(output_dir, 'retriever')\n",
    "                    reader_model_dir = os.path.join(output_dir, 'reader')\n",
    "                    if not os.path.exists(retriever_model_dir):\n",
    "                        os.makedirs(retriever_model_dir)\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    if not os.path.exists(reader_model_dir):\n",
    "                        os.makedirs(reader_model_dir)\n",
    "\n",
    "                    # Take care of distributed/parallel training\n",
    "                    model_to_save = model.module if hasattr(\n",
    "                        model, 'module') else model\n",
    "                    retriever_model_to_save = model_to_save.retriever\n",
    "                    retriever_model_to_save.save_pretrained(\n",
    "                        retriever_model_dir)\n",
    "                    reader_model_to_save = model_to_save.reader\n",
    "                    reader_model_to_save.save_pretrained(reader_model_dir)\n",
    "\n",
    "                    torch.save(args, os.path.join(\n",
    "                        output_dir, 'training_args.bin'))\n",
    "\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        if args.max_steps > 0 and global_step > args.max_steps:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "\n",
    "    if args.local_rank in [-1, 0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:35:11.475038Z",
     "start_time": "2020-05-17T15:35:11.253597Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(args, model, retriever_tokenizer, reader_tokenizer, prefix=\"\"):\n",
    "    if prefix == 'test':\n",
    "        eval_file = args.test_file\n",
    "        orig_eval_file = args.orig_test_file\n",
    "    else:\n",
    "        eval_file = args.dev_file\n",
    "        orig_eval_file = args.orig_dev_file\n",
    "    pytrec_eval_evaluator = evaluator\n",
    "\n",
    "    # dataset, examples, features = load_and_cache_examples(args, tokenizer, evaluate=True, output_examples=True)\n",
    "    DatasetClass = RetrieverDataset\n",
    "    dataset = DatasetClass(eval_file, retriever_tokenizer,\n",
    "                           args.load_small, args.history_num,\n",
    "                           query_max_seq_length=args.retriever_query_max_seq_length,\n",
    "                           is_pretraining=args.is_pretraining,\n",
    "                           given_query=True,\n",
    "                           given_passage=False, \n",
    "                           include_first_for_retriever=args.include_first_for_retriever)\n",
    "\n",
    "    if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
    "        os.makedirs(args.output_dir)\n",
    "    predict_dir = os.path.join(args.output_dir, 'predictions')\n",
    "    if not os.path.exists(predict_dir) and args.local_rank in [-1, 0]:\n",
    "        os.makedirs(predict_dir)\n",
    "\n",
    "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
    "    # Note that DistributedSampler samples randomly\n",
    "    # eval_sampler = SequentialSampler(\n",
    "    #     dataset) if args.local_rank == -1 else DistributedSampler(dataset)\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(\n",
    "        dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, num_workers=args.num_workers)\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        # model.to(f'cuda:{model.device_ids[0]}')\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "    logger.info(\"  Num examples = %d\", len(dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    retriever_run_dict, rarank_run_dict = {}, {}\n",
    "    examples, features = {}, {}\n",
    "    all_results = []\n",
    "    start_time = timeit.default_timer()\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        qids = np.asarray(batch['qid']).reshape(-1).tolist()\n",
    "        # print(qids)\n",
    "        question_texts = np.asarray(\n",
    "            batch['question_text']).reshape(-1).tolist()\n",
    "        answer_texts = np.asarray(\n",
    "            batch['answer_text']).reshape(-1).tolist()\n",
    "        answer_starts = np.asarray(\n",
    "            batch['answer_start']).reshape(-1).tolist()\n",
    "        query_reps = gen_query_reps(args, model, batch)\n",
    "        retrieval_results = retrieve(args, qids, qid_to_idx, query_reps,\n",
    "                                     passage_ids, passage_id_to_idx, passage_reps,\n",
    "                                     qrels, qrels_sparse_matrix,\n",
    "                                     gpu_index, include_positive_passage=False)\n",
    "        retriever_probs = retrieval_results['retriever_probs']\n",
    "        # print('retriever_probs before', retriever_probs)\n",
    "        pids_for_reader = retrieval_results['pids_for_reader']\n",
    "        passages_for_reader = retrieval_results['passages_for_reader']\n",
    "        labels_for_reader = retrieval_results['labels_for_reader']\n",
    "\n",
    "        reader_batch, batch_examples, batch_features = gen_reader_features(qids, question_texts, answer_texts,\n",
    "                                                                           answer_starts, pids_for_reader,\n",
    "                                                                           passages_for_reader, labels_for_reader,\n",
    "                                                                           reader_tokenizer,\n",
    "                                                                           args.reader_max_seq_length,\n",
    "                                                                           is_training=False)\n",
    "        example_ids = reader_batch['example_id']\n",
    "        # print('example_ids', example_ids)\n",
    "        examples.update(batch_examples)\n",
    "        features.update(batch_features)\n",
    "        reader_batch = {k: v.to(args.device)\n",
    "                        for k, v in reader_batch.items() if k != 'example_id'}\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      reader_batch['input_ids'],\n",
    "                      'attention_mask': reader_batch['input_mask'],\n",
    "                      'token_type_ids': reader_batch['segment_ids']}\n",
    "            outputs = model.reader(**inputs)\n",
    "        \n",
    "        retriever_probs = retriever_probs.reshape(-1).tolist()\n",
    "        # print('retriever_probs after', retriever_probs)\n",
    "        for i, example_id in enumerate(example_ids):\n",
    "            result = RawResult(unique_id=example_id,\n",
    "                               start_logits=to_list(outputs[0][i]),\n",
    "                               end_logits=to_list(outputs[1][i]),\n",
    "                               retrieval_logits=to_list(outputs[2][i]), \n",
    "                               retriever_prob=retriever_probs[i])\n",
    "            all_results.append(result)\n",
    "\n",
    "    evalTime = timeit.default_timer() - start_time\n",
    "    logger.info(\"  Evaluation done in total %f secs (%f sec per example)\",\n",
    "                evalTime, evalTime / len(dataset))\n",
    "\n",
    "    output_prediction_file = os.path.join(\n",
    "        predict_dir, \"instance_predictions_{}.json\".format(prefix))\n",
    "    output_nbest_file = os.path.join(\n",
    "        predict_dir, \"instance_nbest_predictions_{}.json\".format(prefix))\n",
    "    output_final_prediction_file = os.path.join(\n",
    "        predict_dir, \"final_predictions_{}.json\".format(prefix))\n",
    "    if args.version_2_with_negative:\n",
    "        output_null_log_odds_file = os.path.join(\n",
    "            predict_dir, \"instance_null_odds_{}.json\".format(prefix))\n",
    "    else:\n",
    "        output_null_log_odds_file = None\n",
    "\n",
    "    all_predictions = write_predictions(examples, features, all_results, args.n_best_size,\n",
    "                                        args.max_answer_length, args.do_lower_case, output_prediction_file,\n",
    "                                        output_nbest_file, output_null_log_odds_file, args.verbose_logging,\n",
    "                                        args.version_2_with_negative, args.null_score_diff_threshold)\n",
    "    write_final_predictions(all_predictions, output_final_prediction_file, \n",
    "                            use_rerank_prob=args.use_rerank_prob, \n",
    "                            use_retriever_prob=args.use_retriever_prob)\n",
    "    eval_metrics = quac_eval(\n",
    "        orig_eval_file, output_final_prediction_file)\n",
    "    rerank_metrics = get_retrieval_metrics(\n",
    "        pytrec_eval_evaluator, all_predictions, eval_retriever_probs=True)\n",
    "    eval_metrics.update(rerank_metrics)\n",
    "\n",
    "    metrics_file = os.path.join(\n",
    "        predict_dir, \"metrics_{}.json\".format(prefix))\n",
    "    with open(metrics_file, 'w') as fout:\n",
    "        json.dump(eval_metrics, fout)\n",
    "\n",
    "    return eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:35:11.703225Z",
     "start_time": "2020-05-17T15:35:11.479917Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_query_reps(args, model, batch):\n",
    "    model.eval()\n",
    "    batch = {k: v.to(args.device) for k, v in batch.items() \n",
    "             if k not in ['example_id', 'qid', 'question_text', 'answer_text', 'answer_start']}\n",
    "    with torch.no_grad():\n",
    "        inputs = {}\n",
    "        inputs['query_input_ids'] = batch['query_input_ids']\n",
    "        inputs['query_attention_mask'] = batch['query_attention_mask']\n",
    "        inputs['query_token_type_ids'] = batch['query_token_type_ids']\n",
    "        outputs = model.retriever(**inputs)\n",
    "        query_reps = outputs[0]\n",
    "\n",
    "    return query_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:35:11.899482Z",
     "start_time": "2020-05-17T15:35:11.707254Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve(args, qids, qid_to_idx, query_reps,\n",
    "             passage_ids, passage_id_to_idx, passage_reps,\n",
    "             qrels, qrels_sparse_matrix,\n",
    "             gpu_index, include_positive_passage=False):\n",
    "    query_reps = query_reps.detach().cpu().numpy()\n",
    "    D, I = gpu_index.search(query_reps, args.top_k_for_retriever)\n",
    "\n",
    "    pidx_for_retriever = np.copy(I)\n",
    "    qidx = [qid_to_idx[qid] for qid in qids]\n",
    "    qidx_expanded = np.expand_dims(qidx, axis=1)\n",
    "    qidx_expanded = np.repeat(qidx_expanded, args.top_k_for_retriever, axis=1)\n",
    "    labels_for_retriever = qrels_sparse_matrix[qidx_expanded, pidx_for_retriever].toarray()\n",
    "    # print('labels_for_retriever before', labels_for_retriever)\n",
    "    if include_positive_passage:\n",
    "        for i, (qid, labels_per_query) in enumerate(zip(qids, labels_for_retriever)):\n",
    "                has_positive = np.sum(labels_per_query)\n",
    "                if not has_positive:\n",
    "                    positive_pid = list(qrels[qid].keys())[0]\n",
    "                    positive_pidx = passage_id_to_idx[positive_pid]\n",
    "                    pidx_for_retriever[i][-1] = positive_pidx\n",
    "        labels_for_retriever = qrels_sparse_matrix[qidx_expanded, pidx_for_retriever].toarray()\n",
    "        # print('labels_for_retriever after', labels_for_retriever)\n",
    "        assert np.sum(labels_for_retriever) >= len(labels_for_retriever)\n",
    "    pids_for_retriever = passage_ids[pidx_for_retriever]\n",
    "    passage_reps_for_retriever = passage_reps[pidx_for_retriever]\n",
    "\n",
    "    scores = D[:, :args.top_k_for_reader]\n",
    "    retriever_probs = sp.special.softmax(scores, axis=1)\n",
    "    pidx_for_reader = I[:, :args.top_k_for_reader]\n",
    "    # print('pidx_for_reader', pidx_for_reader)\n",
    "    # print('qids', qids)\n",
    "    # print('qidx', qidx)\n",
    "    qidx_expanded = np.expand_dims(qidx, axis=1)\n",
    "    qidx_expanded = np.repeat(qidx_expanded, args.top_k_for_reader, axis=1)\n",
    "    # print('qidx_expanded', qidx_expanded)\n",
    "    \n",
    "    labels_for_reader = qrels_sparse_matrix[qidx_expanded, pidx_for_reader].toarray()\n",
    "    # print('labels_for_reader before', labels_for_reader)\n",
    "    # print('labels_for_reader before', labels_for_reader)\n",
    "    if include_positive_passage:\n",
    "        for i, (qid, labels_per_query) in enumerate(zip(qids, labels_for_reader)):\n",
    "                has_positive = np.sum(labels_per_query)\n",
    "                if not has_positive:\n",
    "                    positive_pid = list(qrels[qid].keys())[0]\n",
    "                    positive_pidx = passage_id_to_idx[positive_pid]\n",
    "                    pidx_for_reader[i][-1] = positive_pidx\n",
    "        labels_for_reader = qrels_sparse_matrix[qidx_expanded, pidx_for_reader].toarray()\n",
    "        # print('labels_for_reader after', labels_for_reader)\n",
    "        assert np.sum(labels_for_reader) >= len(labels_for_reader)\n",
    "    # print('labels_for_reader after', labels_for_reader)\n",
    "    pids_for_reader = passage_ids[pidx_for_reader]\n",
    "    # print('pids_for_reader', pids_for_reader)\n",
    "    passages_for_reader = get_passages(pidx_for_reader, args)\n",
    "    # we do not need to modify scores and probs matrices because they will only be\n",
    "    # needed at evaluation, where include_positive_passage will be false\n",
    "\n",
    "    return {'qidx': qidx,\n",
    "            'pidx_for_retriever': pidx_for_retriever,\n",
    "            'pids_for_retriever': pids_for_retriever,\n",
    "            'passage_reps_for_retriever': passage_reps_for_retriever,\n",
    "            'labels_for_retriever': labels_for_retriever,\n",
    "            'retriever_probs': retriever_probs,\n",
    "            'pidx_for_reader': pidx_for_reader,\n",
    "            'pids_for_reader': pids_for_reader,\n",
    "            'passages_for_reader': passages_for_reader, \n",
    "            'labels_for_reader': labels_for_reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:35:12.082015Z",
     "start_time": "2020-05-17T15:35:11.902791Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_passage(i, args):\n",
    "    line = linecache.getline(args.blocks_path, i + 1)\n",
    "    line = json.loads(line.strip())\n",
    "    return line['text']\n",
    "get_passages = np.vectorize(get_passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:36:26.046670Z",
     "start_time": "2020-05-17T15:35:12.085594Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 11:35:13 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "05/17/2020 11:35:13 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/retriever_33/checkpoint-5917/config.json\n",
      "05/17/2020 11:35:13 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"proj_size\": 128,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "05/17/2020 11:35:13 - INFO - transformers.tokenization_utils -   Model name '/mnt/scratch/chenqu/orconvqa_output/retriever_33/' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming '/mnt/scratch/chenqu/orconvqa_output/retriever_33/' is a path or url to a directory containing tokenizer files.\n",
      "05/17/2020 11:35:13 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/retriever_33/spiece.model\n",
      "05/17/2020 11:35:13 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/retriever_33/added_tokens.json\n",
      "05/17/2020 11:35:13 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/retriever_33/special_tokens_map.json\n",
      "05/17/2020 11:35:13 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/retriever_33/tokenizer_config.json\n",
      "05/17/2020 11:35:13 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/retriever_33/checkpoint-5917/config.json\n",
      "05/17/2020 11:35:13 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"proj_size\": 128,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "05/17/2020 11:35:13 - INFO - modeling -   loading weights file /mnt/scratch/chenqu/orconvqa_output/retriever_33/checkpoint-5917/pytorch_model.bin\n",
      "05/17/2020 11:35:15 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /mnt/scratch/chenqu/huggingface_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "05/17/2020 11:35:15 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/17/2020 11:35:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /mnt/scratch/chenqu/huggingface_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/17/2020 11:35:15 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /mnt/scratch/chenqu/huggingface_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "05/17/2020 11:35:18 - INFO - transformers.modeling_utils -   Weights of BertForOrconvqaGlobal not initialized from pretrained model: ['qa_outputs.weight', 'qa_outputs.bias', 'classifier.weight', 'classifier.bias']\n",
      "05/17/2020 11:35:18 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForOrconvqaGlobal: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "05/17/2020 11:35:23 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, best_global_step=40, blocks_path='/mnt/scratch/chenqu/orconvqa/v3/all/all_blocks.txt', dev_file='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/preprocessed/dev.txt', device=device(type='cuda', index=0), do_eval=True, do_lower_case=True, do_test=True, do_train=True, doc_stride=384, eval_all_checkpoints=True, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', given_passage=False, given_query=True, global_mode=True, gradient_accumulation_steps=1, history_num=1, include_first_for_retriever=True, is_pretraining=False, learning_rate=5e-05, load_small=True, local_rank=-1, logging_steps=1, max_answer_length=40, max_grad_norm=1.0, max_steps=-1, n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=1.0, num_workers=2, orig_dev_file='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/quac/dev.txt', orig_test_file='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/quac/test.txt', output_dir='/mnt/scratch/chenqu/orconvqa_output/release_test', overwrite_cache=False, overwrite_output_dir=True, passage_ids_path='/mnt/scratch/chenqu/orconvqa/v5/passage_reps/combined/passage_ids.pkl', passage_reps_path='/mnt/scratch/chenqu/orconvqa/v5/passage_reps/combined/passage_reps.pkl', per_gpu_eval_batch_size=2, per_gpu_train_batch_size=1, prepend_history_answers=False, prepend_history_questions=True, proj_size=128, qa_loss_factor=1.0, qrels='/mnt/scratch/chenqu/orconvqa/v5/retrieval/qrels.txt', reader_cache_dir='/mnt/scratch/chenqu/huggingface_cache/', reader_config_name='', reader_max_query_length=125, reader_max_seq_length=512, reader_model_name_or_path='bert-base-uncased', reader_model_type='bert', reader_tokenizer_dir='/mnt/scratch/chenqu/orconvqa_output/release_test/reader', reader_tokenizer_name='bert-base-uncased', retrieval_loss_factor=1.0, retrieve_checkpoint='/mnt/scratch/chenqu/orconvqa_output/retriever_33/checkpoint-5917', retrieve_tokenizer_dir='/mnt/scratch/chenqu/orconvqa_output/retriever_33/', retriever_cache_dir='/mnt/scratch/chenqu/huggingface_cache/albert_v1/', retriever_config_name='', retriever_model_name_or_path='albert-base-v1', retriever_model_type='albert', retriever_passage_max_seq_length=384, retriever_query_max_seq_length=128, retriever_tokenizer_dir='/mnt/scratch/chenqu/orconvqa_output/release_test/retriever', retriever_tokenizer_name='albert-base-v1', save_steps=20, seed=42, server_ip='', server_port='', test_file='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/preprocessed/test.txt', top_k_for_reader=5, top_k_for_retriever=100, train_file='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/preprocessed/train.txt', use_rerank_prob=True, use_retriever_prob=True, verbose_logging=False, version_2_with_negative=True, warmup_portion=0.1, warmup_steps=0, weight_decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 11:35:23 - INFO - __main__ -   loading passage ids from /mnt/scratch/chenqu/orconvqa/v5/passage_reps/combined/passage_ids.pkl\n",
      "05/17/2020 11:35:44 - INFO - __main__ -   loading passage reps from /mnt/scratch/chenqu/orconvqa/v5/passage_reps/combined/passage_reps.pkl\n",
      "05/17/2020 11:35:54 - INFO - __main__ -   constructing passage faiss_index\n",
      "05/17/2020 11:36:05 - INFO - __main__ -   loading qrels from /mnt/scratch/chenqu/orconvqa/v5/retrieval/qrels.txt\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# arguments shared by the retriever and reader\n",
    "\n",
    "parser.add_argument(\"--train_file\", default='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/preprocessed/train.txt',\n",
    "                    type=str, required=False,\n",
    "                    help=\"open retrieval quac json for training. \")\n",
    "parser.add_argument(\"--dev_file\", default='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/preprocessed/dev.txt',\n",
    "                    type=str, required=False,\n",
    "                    help=\"open retrieval quac json for predictions.\")\n",
    "parser.add_argument(\"--test_file\", default='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/preprocessed/test.txt',\n",
    "                    type=str, required=False,\n",
    "                    help=\"open retrieval quac json for predictions.\")\n",
    "parser.add_argument(\"--orig_dev_file\", default='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/quac/dev.txt',\n",
    "                    type=str, required=False,\n",
    "                    help=\"open retrieval quac json for predictions.\")\n",
    "parser.add_argument(\"--orig_test_file\", default='/mnt/scratch/chenqu/orconvqa/v5/quac_canard/quac/test.txt',\n",
    "                    type=str, required=False,\n",
    "                    help=\"original quac json for evaluation.\")\n",
    "parser.add_argument(\"--qrels\", default='/mnt/scratch/chenqu/orconvqa/v5/retrieval/qrels.txt', type=str, required=False,\n",
    "                    help=\"qrels to evaluate open retrieval\")\n",
    "# parser.add_argument(\"--blocks_path\", default='/mnt/scratch/chenqu/orconvqa/v3/all/all_blocks.txt', type=str, required=False,\n",
    "#                     help=\"all blocks text\")\n",
    "parser.add_argument(\"--blocks_path\", default='/mnt/scratch/chenqu/orconvqa/v3/all/all_blocks.txt', type=str, required=False,\n",
    "                    help=\"all blocks text\")\n",
    "parser.add_argument(\"--passage_reps_path\", default='/mnt/scratch/chenqu/orconvqa/v5/passage_reps/combined/passage_reps.pkl',\n",
    "                    type=str, required=False, help=\"passage representations\")\n",
    "parser.add_argument(\"--passage_ids_path\", default='/mnt/scratch/chenqu/orconvqa/v5/passage_reps/combined/passage_ids.pkl',\n",
    "                    type=str, required=False, help=\"passage ids\")\n",
    "parser.add_argument(\"--output_dir\", default='/mnt/scratch/chenqu/orconvqa_output/release_test', type=str, required=False,\n",
    "                    help=\"The output directory where the model checkpoints and predictions will be written.\")\n",
    "parser.add_argument(\"--load_small\", default=True, type=str2bool, required=False,\n",
    "                    help=\"whether to load just a small portion of data during development\")\n",
    "parser.add_argument(\"--num_workers\", default=2, type=int, required=False,\n",
    "                    help=\"number of workers for dataloader\")\n",
    "\n",
    "parser.add_argument(\"--global_mode\", default=True, type=str2bool, required=False,\n",
    "                    help=\"maxmize the prob of the true answer given all passages\")\n",
    "parser.add_argument(\"--history_num\", default=1, type=int, required=False,\n",
    "                    help=\"number of history turns to use\")\n",
    "parser.add_argument(\"--prepend_history_questions\", default=True, type=str2bool, required=False,\n",
    "                    help=\"whether to prepend history questions to the current question\")\n",
    "parser.add_argument(\"--prepend_history_answers\", default=False, type=str2bool, required=False,\n",
    "                    help=\"whether to prepend history answers to the current question\")\n",
    "\n",
    "parser.add_argument(\"--do_train\", default=True, type=str2bool,\n",
    "                    help=\"Whether to run training.\")\n",
    "parser.add_argument(\"--do_eval\", default=True, type=str2bool,\n",
    "                    help=\"Whether to run eval on the dev set.\")\n",
    "parser.add_argument(\"--do_test\", default=True, type=str2bool,\n",
    "                    help=\"Whether to run eval on the test set.\")\n",
    "parser.add_argument(\"--best_global_step\", default=40, type=int, required=False,\n",
    "                    help=\"used when only do_test\")\n",
    "parser.add_argument(\"--evaluate_during_training\", default=False, type=str2bool,\n",
    "                    help=\"Rul evaluation during training at each logging step.\")\n",
    "parser.add_argument(\"--do_lower_case\", default=True, type=str2bool,\n",
    "                    help=\"Set this flag if you are using an uncased model.\")\n",
    "\n",
    "parser.add_argument(\"--per_gpu_train_batch_size\", default=1, type=int,\n",
    "                    help=\"Batch size per GPU/CPU for training.\")\n",
    "parser.add_argument(\"--per_gpu_eval_batch_size\", default=2, type=int,\n",
    "                    help=\"Batch size per GPU/CPU for evaluation.\")\n",
    "parser.add_argument(\"--learning_rate\", default=5e-5, type=float,\n",
    "                    help=\"The initial learning rate for Adam.\")\n",
    "parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n",
    "                    help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n",
    "                    help=\"Weight decay if we apply some.\")\n",
    "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float,\n",
    "                    help=\"Epsilon for Adam optimizer.\")\n",
    "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n",
    "                    help=\"Max gradient norm.\")\n",
    "parser.add_argument(\"--num_train_epochs\", default=1.0, type=float,\n",
    "                    help=\"Total number of training epochs to perform.\")\n",
    "parser.add_argument(\"--max_steps\", default=-1, type=int,\n",
    "                    help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
    "parser.add_argument(\"--warmup_steps\", default=0, type=int,\n",
    "                    help=\"Linear warmup over warmup_steps.\")\n",
    "parser.add_argument(\"--warmup_portion\", default=0.1, type=float,\n",
    "                    help=\"Linear warmup over warmup_steps (=t_total * warmup_portion). override warmup_steps \")\n",
    "parser.add_argument(\"--verbose_logging\", action='store_true',\n",
    "                    help=\"If true, all of the warnings related to data processing will be printed. \"\n",
    "                         \"A number of warnings are expected for a normal SQuAD evaluation.\")\n",
    "\n",
    "parser.add_argument('--logging_steps', type=int, default=1,\n",
    "                    help=\"Log every X updates steps.\")\n",
    "parser.add_argument('--save_steps', type=int, default=20,\n",
    "                    help=\"Save checkpoint every X updates steps.\")\n",
    "parser.add_argument(\"--eval_all_checkpoints\", default=True, type=str2bool,\n",
    "                    help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\")\n",
    "parser.add_argument(\"--no_cuda\", default=False, type=str2bool,\n",
    "                    help=\"Whether not to use CUDA when available\")\n",
    "parser.add_argument('--overwrite_output_dir', default=True, type=str2bool,\n",
    "                    help=\"Overwrite the content of the output directory\")\n",
    "parser.add_argument('--overwrite_cache', action='store_true',\n",
    "                    help=\"Overwrite the cached training and evaluation sets\")\n",
    "parser.add_argument('--seed', type=int, default=42,\n",
    "                    help=\"random seed for initialization\")\n",
    "\n",
    "parser.add_argument(\"--local_rank\", type=int, default=-1,\n",
    "                    help=\"local_rank for distributed training on gpus\")\n",
    "parser.add_argument('--fp16', default=False, type=str2bool,\n",
    "                    help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\")\n",
    "parser.add_argument('--fp16_opt_level', type=str, default='O1',\n",
    "                    help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "                         \"See details at https://nvidia.github.io/apex/amp.html\")\n",
    "parser.add_argument('--server_ip', type=str, default='',\n",
    "                    help=\"Can be used for distant debugging.\")\n",
    "parser.add_argument('--server_port', type=str, default='',\n",
    "                    help=\"Can be used for distant debugging.\")\n",
    "\n",
    "# retriever arguments\n",
    "parser.add_argument(\"--retriever_config_name\", default=\"\", type=str,\n",
    "                    help=\"Pretrained config name or path if not the same as model_name\")\n",
    "parser.add_argument(\"--retriever_model_type\", default='albert', type=str, required=False,\n",
    "                    help=\"retriever model type\")\n",
    "parser.add_argument(\"--retriever_model_name_or_path\", default='albert-base-v1', type=str, required=False,\n",
    "                    help=\"retriever model name\")\n",
    "parser.add_argument(\"--retriever_tokenizer_name\", default=\"albert-base-v1\", type=str,\n",
    "                    help=\"Pretrained tokenizer name or path if not the same as model_name\")\n",
    "parser.add_argument(\"--retriever_cache_dir\", default=\"/mnt/scratch/chenqu/huggingface_cache/albert_v1/\", type=str,\n",
    "                    help=\"Where do you want to store the pre-trained models downloaded from s3\")\n",
    "parser.add_argument(\"--retrieve_checkpoint\",\n",
    "                    default='/mnt/scratch/chenqu/orconvqa_output/retriever_33/checkpoint-5917', type=str,\n",
    "                    help=\"generate query/passage representations with this checkpoint\")\n",
    "parser.add_argument(\"--retrieve_tokenizer_dir\",\n",
    "                    default='/mnt/scratch/chenqu/orconvqa_output/retriever_33/', type=str,\n",
    "                    help=\"dir that contains tokenizer files\")\n",
    "\n",
    "parser.add_argument(\"--given_query\", default=True, type=str2bool,\n",
    "                    help=\"Whether query is given.\")\n",
    "parser.add_argument(\"--given_passage\", default=False, type=str2bool,\n",
    "                    help=\"Whether passage is given. Passages are not given when jointly train\")\n",
    "parser.add_argument(\"--is_pretraining\", default=False, type=str2bool,\n",
    "                    help=\"Whether is pretraining. We fine tune the query encoder in retriever\")\n",
    "parser.add_argument(\"--include_first_for_retriever\", default=True, type=str2bool,\n",
    "                    help=\"include the first question in a dialog in addition to history_num for retriever (not reader)\")\n",
    "# parser.add_argument(\"--only_positive_passage\", default=True, type=str2bool,\n",
    "#                     help=\"we only pass the positive passages, the rest of the passges in the batch are considered as negatives\")\n",
    "parser.add_argument(\"--retriever_query_max_seq_length\", default=128, type=int,\n",
    "                    help=\"The maximum input sequence length of query.\")\n",
    "parser.add_argument(\"--retriever_passage_max_seq_length\", default=384, type=int,\n",
    "                    help=\"The maximum input sequence length of passage (384 + [CLS] + [SEP]).\")\n",
    "parser.add_argument(\"--proj_size\", default=128, type=int,\n",
    "                    help=\"The size of the query/passage rep after projection of [CLS] rep.\")\n",
    "parser.add_argument(\"--top_k_for_retriever\", default=100, type=int,\n",
    "                    help=\"retrieve top k passages for a query, these passages will be used to update the query encoder\")\n",
    "parser.add_argument(\"--use_retriever_prob\", default=True, type=str2bool,\n",
    "                    help=\"include albert retriever probs in final answer ranking\")\n",
    "\n",
    "# reader arguments\n",
    "parser.add_argument(\"--reader_config_name\", default=\"\", type=str,\n",
    "                    help=\"Pretrained config name or path if not the same as model_name\")\n",
    "parser.add_argument(\"--reader_model_name_or_path\", default='bert-base-uncased', type=str, required=False,\n",
    "                    help=\"reader model name\")\n",
    "parser.add_argument(\"--reader_model_type\", default='bert', type=str, required=False,\n",
    "                    help=\"reader model type\")\n",
    "parser.add_argument(\"--reader_tokenizer_name\", default=\"bert-base-uncased\", type=str,\n",
    "                    help=\"Pretrained tokenizer name or path if not the same as model_name\")\n",
    "parser.add_argument(\"--reader_cache_dir\", default=\"/mnt/scratch/chenqu/huggingface_cache/\", type=str,\n",
    "                    help=\"Where do you want to store the pre-trained models downloaded from s3\")\n",
    "parser.add_argument(\"--reader_max_seq_length\", default=512, type=int,\n",
    "                    help=\"The maximum total input sequence length after WordPiece tokenization. Sequences \"\n",
    "                         \"longer than this will be truncated, and sequences shorter than this will be padded.\")\n",
    "parser.add_argument(\"--doc_stride\", default=384, type=int,\n",
    "                    help=\"When splitting up a long document into chunks, how much stride to take between chunks.\")\n",
    "parser.add_argument('--version_2_with_negative', default=True, type=str2bool, required=False,\n",
    "                    help='If true, the SQuAD examples contain some that do not have an answer.')\n",
    "parser.add_argument('--null_score_diff_threshold', type=float, default=0.0,\n",
    "                    help=\"If null_score - best_non_null is greater than the threshold predict null.\")\n",
    "parser.add_argument(\"--reader_max_query_length\", default=125, type=int,\n",
    "                    help=\"The maximum number of tokens for the question. Questions longer than this will \"\n",
    "                         \"be truncated to this length.\")\n",
    "parser.add_argument(\"--n_best_size\", default=20, type=int,\n",
    "                    help=\"The total number of n-best predictions to generate in the nbest_predictions.json output file.\")\n",
    "parser.add_argument(\"--max_answer_length\", default=40, type=int,\n",
    "                    help=\"The maximum length of an answer that can be generated. This is needed because the start \"\n",
    "                         \"and end predictions are not conditioned on one another.\")\n",
    "parser.add_argument(\"--qa_loss_factor\", default=1.0, type=float,\n",
    "                    help=\"total_loss = qa_loss_factor * qa_loss + retrieval_loss_factor * retrieval_loss\")\n",
    "parser.add_argument(\"--retrieval_loss_factor\", default=1.0, type=float,\n",
    "                    help=\"total_loss = qa_loss_factor * qa_loss + retrieval_loss_factor * retrieval_loss\")\n",
    "parser.add_argument(\"--top_k_for_reader\", default=5, type=int,\n",
    "                    help=\"update the reader with top k passages\")\n",
    "parser.add_argument(\"--use_rerank_prob\", default=True, type=str2bool,\n",
    "                    help=\"include rerank probs in final answer ranking\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "if os.path.exists(args.output_dir) and os.listdir(args.output_dir) and args.do_train and not args.overwrite_output_dir:\n",
    "    raise ValueError(\n",
    "        \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args.output_dir))\n",
    "args.retriever_tokenizer_dir = os.path.join(args.output_dir, 'retriever')\n",
    "args.reader_tokenizer_dir = os.path.join(args.output_dir, 'reader')\n",
    "# Setup distant debugging if needed\n",
    "if args.server_ip and args.server_port:\n",
    "    # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
    "    import ptvsd\n",
    "    print(\"Waiting for debugger attach\")\n",
    "    ptvsd.enable_attach(\n",
    "        address=(args.server_ip, args.server_port), redirect_output=True)\n",
    "    ptvsd.wait_for_attach()\n",
    "\n",
    "# Setup CUDA, GPU & distributed training\n",
    "# we now only support joint training on a single card\n",
    "# we will request two cards, one for torch and the other one for faiss\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\n",
    "        \"cuda:0\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    # args.n_gpu = torch.cuda.device_count()\n",
    "    args.n_gpu = 1\n",
    "    # torch.cuda.set_device(0)\n",
    "else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "    args.n_gpu = 1\n",
    "args.device = device\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN)\n",
    "logger.warning(\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "               args.local_rank, device, args.n_gpu, bool(args.local_rank != -1), args.fp16)\n",
    "\n",
    "# Set seed\n",
    "set_seed(args)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "if args.local_rank not in [-1, 0]:\n",
    "    # Make sure only the first process in distributed training will download model & vocab\n",
    "    torch.distributed.barrier()\n",
    "\n",
    "\n",
    "model = Pipeline()\n",
    "\n",
    "args.retriever_model_type = args.retriever_model_type.lower()\n",
    "retriever_config_class, retriever_model_class, retriever_tokenizer_class = MODEL_CLASSES['retriever']\n",
    "retriever_config = retriever_config_class.from_pretrained(args.retrieve_checkpoint)\n",
    "\n",
    "# load pretrained retriever\n",
    "retriever_tokenizer = retriever_tokenizer_class.from_pretrained(args.retrieve_tokenizer_dir)\n",
    "retriever_model = retriever_model_class.from_pretrained(args.retrieve_checkpoint, force_download=True)\n",
    "\n",
    "model.retriever = retriever_model\n",
    "# do not need and do not tune passage encoder\n",
    "model.retriever.passage_encoder = None\n",
    "model.retriever.passage_proj = None\n",
    "\n",
    "args.reader_model_type = args.reader_model_type.lower()\n",
    "reader_config_class, reader_model_class, reader_tokenizer_class = MODEL_CLASSES['reader']\n",
    "reader_config = reader_config_class.from_pretrained(args.reader_config_name if args.reader_config_name else args.reader_model_name_or_path,\n",
    "                                                    cache_dir=args.reader_cache_dir if args.reader_cache_dir else None)\n",
    "reader_config.num_qa_labels = 2\n",
    "# this not used for BertForOrconvqaGlobal\n",
    "reader_config.num_retrieval_labels = 2\n",
    "reader_config.qa_loss_factor = args.qa_loss_factor\n",
    "reader_config.retrieval_loss_factor = args.retrieval_loss_factor\n",
    "\n",
    "reader_tokenizer = reader_tokenizer_class.from_pretrained(args.reader_tokenizer_name if args.reader_tokenizer_name else args.reader_model_name_or_path,\n",
    "                                                          do_lower_case=args.do_lower_case,\n",
    "                                                          cache_dir=args.reader_cache_dir if args.reader_cache_dir else None)\n",
    "reader_model = reader_model_class.from_pretrained(args.reader_model_name_or_path,\n",
    "                                                  from_tf=bool(\n",
    "                                                      '.ckpt' in args.reader_model_name_or_path),\n",
    "                                                  config=reader_config,\n",
    "                                                  cache_dir=args.reader_cache_dir if args.reader_cache_dir else None)\n",
    "\n",
    "model.reader = reader_model\n",
    "\n",
    "if args.local_rank == 0:\n",
    "    # Make sure only the first process in distributed training will download model & vocab\n",
    "    torch.distributed.barrier()\n",
    "\n",
    "model.to(args.device)\n",
    "\n",
    "logger.info(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "# Before we do anything with models, we want to ensure that we get fp16 execution of torch.einsum if args.fp16 is set.\n",
    "# Otherwise it'll default to \"promote\" mode, and we'll get fp32 operations. Note that running `--fp16_opt_level=\"O2\"` will\n",
    "# remove the need for this code, but it is still valid.\n",
    "if args.fp16:\n",
    "    try:\n",
    "        import apex\n",
    "        apex.amp.register_half_function(torch, 'einsum')\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "\n",
    "logger.info(f'loading passage ids from {args.passage_ids_path}')\n",
    "with open(args.passage_ids_path, 'rb') as handle:\n",
    "    passage_ids = pkl.load(handle)\n",
    "\n",
    "logger.info(f'loading passage reps from {args.passage_reps_path}')\n",
    "with open(args.passage_reps_path, 'rb') as handle:\n",
    "    passage_reps = pkl.load(handle)\n",
    "\n",
    "logger.info('constructing passage faiss_index')\n",
    "faiss_res = faiss.StandardGpuResources() \n",
    "index = faiss.IndexFlatIP(args.proj_size)\n",
    "index.add(passage_reps)\n",
    "gpu_index = faiss.index_cpu_to_gpu(faiss_res, 1, index)\n",
    "\n",
    "# logger.info(f'loading all blocks from {args.blocks_path}')\n",
    "# with open(args.blocks_path, 'rb') as handle:\n",
    "#     blocks_array = pkl.load(handle)\n",
    "\n",
    "\n",
    "logger.info(f'loading qrels from {args.qrels}')\n",
    "with open(args.qrels) as handle:\n",
    "    qrels = json.load(handle)\n",
    "\n",
    "passage_id_to_idx = {}\n",
    "for i, pid in enumerate(passage_ids):\n",
    "    passage_id_to_idx[pid] = i\n",
    "\n",
    "qrels_data, qrels_row_idx, qrels_col_idx = [], [], []\n",
    "qid_to_idx = {}\n",
    "for i, (qid, v) in enumerate(qrels.items()):\n",
    "    qid_to_idx[qid] = i\n",
    "    for pid in v.keys():\n",
    "        qrels_data.append(1)\n",
    "        qrels_row_idx.append(i)\n",
    "        qrels_col_idx.append(passage_id_to_idx[pid])\n",
    "qrels_sparse_matrix = sp.sparse.csr_matrix(\n",
    "    (qrels_data, (qrels_row_idx, qrels_col_idx)))\n",
    "\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'recip_rank', 'recall'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:38:44.168376Z",
     "start_time": "2020-05-17T15:36:26.049099Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 11:36:26 - INFO - __main__ -   ***** Running training *****\n",
      "05/17/2020 11:36:26 - INFO - __main__ -     Num examples = 50\n",
      "05/17/2020 11:36:26 - INFO - __main__ -     Num Epochs = 1\n",
      "05/17/2020 11:36:26 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
      "05/17/2020 11:36:26 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "05/17/2020 11:36:26 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "05/17/2020 11:36:26 - INFO - __main__ -     Total optimization steps = 50\n",
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 1/50 [01:27<1:11:24, 87.45s/it]\u001b[A\n",
      "Iteration:   4%|▍         | 2/50 [01:28<49:09, 61.45s/it]  \u001b[A\n",
      "Iteration:   6%|▌         | 3/50 [01:28<33:51, 43.23s/it]\u001b[A\n",
      "Iteration:   8%|▊         | 4/50 [01:29<23:21, 30.47s/it]\u001b[A\n",
      "Iteration:  10%|█         | 5/50 [01:30<16:10, 21.57s/it]\u001b[A\n",
      "Iteration:  12%|█▏        | 6/50 [01:31<11:14, 15.33s/it]\u001b[A\n",
      "Iteration:  14%|█▍        | 7/50 [01:32<07:51, 10.96s/it]\u001b[A\n",
      "Iteration:  16%|█▌        | 8/50 [01:32<05:31,  7.90s/it]\u001b[A\n",
      "Iteration:  18%|█▊        | 9/50 [01:33<03:56,  5.76s/it]\u001b[A\n",
      "Iteration:  20%|██        | 10/50 [01:34<02:50,  4.27s/it]\u001b[A\n",
      "Iteration:  22%|██▏       | 11/50 [01:35<02:05,  3.22s/it]\u001b[A\n",
      "Iteration:  24%|██▍       | 12/50 [01:35<01:34,  2.49s/it]\u001b[A\n",
      "Iteration:  26%|██▌       | 13/50 [01:36<01:13,  1.98s/it]\u001b[A\n",
      "Iteration:  28%|██▊       | 14/50 [01:37<00:58,  1.62s/it]\u001b[A\n",
      "Iteration:  30%|███       | 15/50 [01:38<00:47,  1.36s/it]\u001b[A\n",
      "Iteration:  32%|███▏      | 16/50 [01:38<00:40,  1.19s/it]\u001b[A\n",
      "Iteration:  34%|███▍      | 17/50 [01:39<00:35,  1.07s/it]\u001b[A\n",
      "Iteration:  36%|███▌      | 18/50 [01:40<00:31,  1.02it/s]\u001b[A05/17/2020 11:38:07 - INFO - transformers.configuration_utils -   Configuration saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/retriever/config.json\n",
      "05/17/2020 11:38:07 - INFO - transformers.modeling_utils -   Model weights saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/retriever/pytorch_model.bin\n",
      "05/17/2020 11:38:07 - INFO - transformers.configuration_utils -   Configuration saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/reader/config.json\n",
      "05/17/2020 11:38:07 - INFO - transformers.modeling_utils -   Model weights saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/reader/pytorch_model.bin\n",
      "05/17/2020 11:38:07 - INFO - __main__ -   Saving model checkpoint to /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20\n",
      "\n",
      "Iteration:  38%|███▊      | 19/50 [01:41<00:32,  1.04s/it]\u001b[A\n",
      "Iteration:  40%|████      | 20/50 [01:42<00:28,  1.06it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 21/50 [01:43<00:26,  1.11it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 22/50 [01:44<00:24,  1.15it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 23/50 [01:44<00:22,  1.18it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 24/50 [01:45<00:21,  1.20it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 25/50 [01:46<00:20,  1.21it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 26/50 [01:47<00:19,  1.24it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 27/50 [01:48<00:18,  1.25it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 28/50 [01:48<00:17,  1.25it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 29/50 [01:49<00:16,  1.25it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 30/50 [01:50<00:15,  1.25it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 31/50 [01:52<00:19,  1.05s/it]\u001b[A\n",
      "Iteration:  64%|██████▍   | 32/50 [01:52<00:17,  1.03it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 33/50 [01:53<00:15,  1.08it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 34/50 [01:54<00:14,  1.12it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 35/50 [01:55<00:13,  1.15it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 36/50 [01:56<00:12,  1.16it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 37/50 [01:56<00:10,  1.19it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 38/50 [01:57<00:10,  1.20it/s]\u001b[A05/17/2020 11:38:24 - INFO - transformers.configuration_utils -   Configuration saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40/retriever/config.json\n",
      "05/17/2020 11:38:24 - INFO - transformers.modeling_utils -   Model weights saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40/retriever/pytorch_model.bin\n",
      "05/17/2020 11:38:24 - INFO - transformers.configuration_utils -   Configuration saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40/reader/config.json\n",
      "05/17/2020 11:38:25 - INFO - transformers.modeling_utils -   Model weights saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40/reader/pytorch_model.bin\n",
      "05/17/2020 11:38:25 - INFO - __main__ -   Saving model checkpoint to /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40\n",
      "\n",
      "Iteration:  78%|███████▊  | 39/50 [01:58<00:10,  1.05it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 40/50 [01:59<00:09,  1.09it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 41/50 [02:00<00:08,  1.06it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 42/50 [02:01<00:07,  1.10it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 43/50 [02:02<00:06,  1.13it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 44/50 [02:03<00:05,  1.15it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 45/50 [02:04<00:04,  1.16it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 46/50 [02:04<00:03,  1.18it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 47/50 [02:05<00:02,  1.19it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 48/50 [02:06<00:01,  1.19it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 49/50 [02:07<00:00,  1.20it/s]\u001b[A\n",
      "Epoch: 100%|██████████| 1/1 [02:08<00:00, 128.86s/it]it/s]\u001b[A\n",
      "05/17/2020 11:38:35 - INFO - __main__ -    global_step = 51, average loss = 9.899379393633675\n",
      "05/17/2020 11:38:35 - INFO - __main__ -   Saving model checkpoint to /mnt/scratch/chenqu/orconvqa_output/release_test\n",
      "05/17/2020 11:38:35 - INFO - transformers.configuration_utils -   Configuration saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/retriever/config.json\n",
      "05/17/2020 11:38:35 - INFO - transformers.modeling_utils -   Model weights saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/retriever/pytorch_model.bin\n",
      "05/17/2020 11:38:35 - INFO - transformers.configuration_utils -   Configuration saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/reader/config.json\n",
      "05/17/2020 11:38:35 - INFO - transformers.modeling_utils -   Model weights saved in /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/reader/pytorch_model.bin\n",
      "05/17/2020 11:38:35 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/retriever/config.json\n",
      "05/17/2020 11:38:35 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"proj_size\": 128,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "05/17/2020 11:38:35 - INFO - modeling -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/retriever/pytorch_model.bin\n",
      "05/17/2020 11:38:36 - INFO - modeling -   Weights of AlbertForRetrieverOnlyPositivePassage not initialized from pretrained model: ['passage_encoder.embeddings.word_embeddings.weight', 'passage_encoder.embeddings.position_embeddings.weight', 'passage_encoder.embeddings.token_type_embeddings.weight', 'passage_encoder.embeddings.LayerNorm.weight', 'passage_encoder.embeddings.LayerNorm.bias', 'passage_encoder.encoder.embedding_hidden_mapping_in.weight', 'passage_encoder.encoder.embedding_hidden_mapping_in.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'passage_encoder.pooler.weight', 'passage_encoder.pooler.bias', 'passage_proj.weight', 'passage_proj.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 11:38:36 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/reader/config.json\n",
      "05/17/2020 11:38:36 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_qa_labels\": 2,\n",
      "  \"num_retrieval_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_loss_factor\": 1.0,\n",
      "  \"retrieval_loss_factor\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/17/2020 11:38:36 - INFO - transformers.modeling_utils -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/reader/pytorch_model.bin\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   Model name '/mnt/scratch/chenqu/orconvqa_output/release_test/retriever' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming '/mnt/scratch/chenqu/orconvqa_output/release_test/retriever' is a path or url to a directory containing tokenizer files.\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/retriever/spiece.model\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/retriever/added_tokens.json\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/retriever/special_tokens_map.json\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/retriever/tokenizer_config.json\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   Model name '/mnt/scratch/chenqu/orconvqa_output/release_test/reader' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming '/mnt/scratch/chenqu/orconvqa_output/release_test/reader' is a path or url to a directory containing tokenizer files.\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/reader/vocab.txt\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/reader/added_tokens.json\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/reader/special_tokens_map.json\n",
      "05/17/2020 11:38:39 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/reader/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "if args.do_train:\n",
    "    DatasetClass = RetrieverDataset\n",
    "    train_dataset = DatasetClass(args.train_file, retriever_tokenizer,\n",
    "                                 args.load_small, args.history_num,\n",
    "                                 query_max_seq_length=args.retriever_query_max_seq_length,\n",
    "                                 is_pretraining=args.is_pretraining,\n",
    "                                 given_query=True,\n",
    "                                 given_passage=False, \n",
    "                                 include_first_for_retriever=args.include_first_for_retriever)\n",
    "    global_step, tr_loss = train(\n",
    "        args, train_dataset, model, retriever_tokenizer, reader_tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\",\n",
    "                global_step, tr_loss)\n",
    "\n",
    "# Save the trained model and the tokenizer\n",
    "if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
    "    # Create output directory if needed\n",
    "    if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
    "        os.makedirs(args.output_dir)\n",
    "    if not os.path.exists(args.retriever_tokenizer_dir) and args.local_rank in [-1, 0]:\n",
    "        os.makedirs(args.retriever_tokenizer_dir)\n",
    "    if not os.path.exists(args.reader_tokenizer_dir) and args.local_rank in [-1, 0]:\n",
    "        os.makedirs(args.reader_tokenizer_dir)\n",
    "\n",
    "    logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
    "    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "    # They can then be reloaded using `from_pretrained()`\n",
    "    # Take care of distributed/parallel training\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    final_checkpoint_output_dir = os.path.join(\n",
    "        args.output_dir, 'checkpoint-{}'.format(global_step))\n",
    "    final_retriever_model_dir = os.path.join(\n",
    "        final_checkpoint_output_dir, 'retriever')\n",
    "    final_reader_model_dir = os.path.join(\n",
    "        final_checkpoint_output_dir, 'reader')\n",
    "    if not os.path.exists(final_checkpoint_output_dir):\n",
    "        os.makedirs(final_checkpoint_output_dir)\n",
    "    if not os.path.exists(final_retriever_model_dir):\n",
    "        os.makedirs(final_retriever_model_dir)\n",
    "    if not os.path.exists(final_reader_model_dir):\n",
    "        os.makedirs(final_reader_model_dir)\n",
    "\n",
    "    retriever_model_to_save = model_to_save.retriever\n",
    "    retriever_model_to_save.save_pretrained(\n",
    "        final_retriever_model_dir)\n",
    "    reader_model_to_save = model_to_save.reader\n",
    "    reader_model_to_save.save_pretrained(final_reader_model_dir)\n",
    "\n",
    "    retriever_tokenizer.save_pretrained(args.retriever_tokenizer_dir)\n",
    "    reader_tokenizer.save_pretrained(args.reader_tokenizer_dir)\n",
    "\n",
    "    # Good practice: save your training arguments together with the trained model\n",
    "    torch.save(args, os.path.join(\n",
    "        final_checkpoint_output_dir, 'training_args.bin'))\n",
    "\n",
    "    # Load a trained model and vocabulary that you have fine-tuned\n",
    "    model = Pipeline()\n",
    "\n",
    "    model.retriever = retriever_model_class.from_pretrained(\n",
    "        final_retriever_model_dir, force_download=True)\n",
    "    model.retriever.passage_encoder = None\n",
    "    model.retriever.passage_proj = None\n",
    "\n",
    "    model.reader = reader_model_class.from_pretrained(\n",
    "        final_reader_model_dir, force_download=True)\n",
    "\n",
    "    retriever_tokenizer = retriever_tokenizer_class.from_pretrained(\n",
    "        args.retriever_tokenizer_dir, do_lower_case=args.do_lower_case)\n",
    "    reader_tokenizer = reader_tokenizer_class.from_pretrained(\n",
    "        args.reader_tokenizer_dir, do_lower_case=args.do_lower_case)\n",
    "    model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:40:08.952116Z",
     "start_time": "2020-05-17T15:38:44.170749Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   Model name '/mnt/scratch/chenqu/orconvqa_output/release_test/retriever' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming '/mnt/scratch/chenqu/orconvqa_output/release_test/retriever' is a path or url to a directory containing tokenizer files.\n",
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/retriever/spiece.model\n",
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/retriever/added_tokens.json\n",
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/retriever/special_tokens_map.json\n",
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/retriever/tokenizer_config.json\n",
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   Model name '/mnt/scratch/chenqu/orconvqa_output/release_test/reader' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming '/mnt/scratch/chenqu/orconvqa_output/release_test/reader' is a path or url to a directory containing tokenizer files.\n",
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/reader/vocab.txt\n",
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/reader/added_tokens.json\n",
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/reader/special_tokens_map.json\n",
      "05/17/2020 11:38:44 - INFO - transformers.tokenization_utils -   loading file /mnt/scratch/chenqu/orconvqa_output/release_test/reader/tokenizer_config.json\n",
      "05/17/2020 11:38:44 - INFO - __main__ -   Evaluate the following checkpoints: ['/mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20', '/mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40', '/mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51']\n",
      "05/17/2020 11:38:44 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/retriever/config.json\n",
      "05/17/2020 11:38:44 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"proj_size\": 128,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "05/17/2020 11:38:44 - INFO - modeling -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/retriever/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 global_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 11:38:45 - INFO - modeling -   Weights of AlbertForRetrieverOnlyPositivePassage not initialized from pretrained model: ['passage_encoder.embeddings.word_embeddings.weight', 'passage_encoder.embeddings.position_embeddings.weight', 'passage_encoder.embeddings.token_type_embeddings.weight', 'passage_encoder.embeddings.LayerNorm.weight', 'passage_encoder.embeddings.LayerNorm.bias', 'passage_encoder.encoder.embedding_hidden_mapping_in.weight', 'passage_encoder.encoder.embedding_hidden_mapping_in.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'passage_encoder.pooler.weight', 'passage_encoder.pooler.bias', 'passage_proj.weight', 'passage_proj.bias']\n",
      "05/17/2020 11:38:45 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/reader/config.json\n",
      "05/17/2020 11:38:45 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_qa_labels\": 2,\n",
      "  \"num_retrieval_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_loss_factor\": 1.0,\n",
      "  \"retrieval_loss_factor\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/17/2020 11:38:45 - INFO - transformers.modeling_utils -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/reader/pytorch_model.bin\n",
      "05/17/2020 11:38:51 - INFO - __main__ -   ***** Running evaluation 20 *****\n",
      "05/17/2020 11:38:51 - INFO - __main__ -     Num examples = 50\n",
      "05/17/2020 11:38:51 - INFO - __main__ -     Batch size = 2\n",
      "Evaluating: 100%|██████████| 25/25 [00:17<00:00,  1.57it/s]\n",
      "05/17/2020 11:39:09 - INFO - __main__ -     Evaluation done in total 18.137406 secs (0.362748 sec per example)\n",
      "05/17/2020 11:39:09 - INFO - utils -   Writing predictions to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/instance_predictions_20.json\n",
      "05/17/2020 11:39:09 - INFO - utils -   Writing nbest to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/instance_nbest_predictions_20.json\n",
      "05/17/2020 11:39:11 - INFO - utils -   Writing final predictions to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/final_predictions_20.json\n",
      "05/17/2020 11:39:11 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40/retriever/config.json\n",
      "05/17/2020 11:39:11 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"proj_size\": 128,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "05/17/2020 11:39:11 - INFO - modeling -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40/retriever/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall F1: 0.1\n",
      "Yes/No Accuracy : 1.1\n",
      "Followup Accuracy : 0.7\n",
      "Unfiltered F1 (3430 questions): 0.1\n",
      "Accuracy On Unanswerable Questions: 0.0 %% (602 questions)\n",
      "Human F1: 100.0\n",
      "Model F1 >= Human F1 (Questions): 0 / 3430, 0.0%\n",
      "Model F1 >= Human F1 (Dialogs): 0 / 490, 0.0%\n",
      "=======================\n",
      "40 global_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 11:39:12 - INFO - modeling -   Weights of AlbertForRetrieverOnlyPositivePassage not initialized from pretrained model: ['passage_encoder.embeddings.word_embeddings.weight', 'passage_encoder.embeddings.position_embeddings.weight', 'passage_encoder.embeddings.token_type_embeddings.weight', 'passage_encoder.embeddings.LayerNorm.weight', 'passage_encoder.embeddings.LayerNorm.bias', 'passage_encoder.encoder.embedding_hidden_mapping_in.weight', 'passage_encoder.encoder.embedding_hidden_mapping_in.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'passage_encoder.pooler.weight', 'passage_encoder.pooler.bias', 'passage_proj.weight', 'passage_proj.bias']\n",
      "05/17/2020 11:39:12 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40/reader/config.json\n",
      "05/17/2020 11:39:12 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_qa_labels\": 2,\n",
      "  \"num_retrieval_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_loss_factor\": 1.0,\n",
      "  \"retrieval_loss_factor\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/17/2020 11:39:12 - INFO - transformers.modeling_utils -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-40/reader/pytorch_model.bin\n",
      "05/17/2020 11:39:18 - INFO - __main__ -   ***** Running evaluation 40 *****\n",
      "05/17/2020 11:39:18 - INFO - __main__ -     Num examples = 50\n",
      "05/17/2020 11:39:18 - INFO - __main__ -     Batch size = 2\n",
      "Evaluating: 100%|██████████| 25/25 [00:17<00:00,  1.58it/s]\n",
      "05/17/2020 11:39:36 - INFO - __main__ -     Evaluation done in total 18.143787 secs (0.362876 sec per example)\n",
      "05/17/2020 11:39:36 - INFO - utils -   Writing predictions to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/instance_predictions_40.json\n",
      "05/17/2020 11:39:36 - INFO - utils -   Writing nbest to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/instance_nbest_predictions_40.json\n",
      "05/17/2020 11:39:38 - INFO - utils -   Writing final predictions to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/final_predictions_40.json\n",
      "05/17/2020 11:39:38 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/retriever/config.json\n",
      "05/17/2020 11:39:38 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"proj_size\": 128,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "05/17/2020 11:39:38 - INFO - modeling -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/retriever/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall F1: 0.1\n",
      "Yes/No Accuracy : 1.1\n",
      "Followup Accuracy : 0.7\n",
      "Unfiltered F1 (3430 questions): 0.1\n",
      "Accuracy On Unanswerable Questions: 0.0 %% (602 questions)\n",
      "Human F1: 100.0\n",
      "Model F1 >= Human F1 (Questions): 0 / 3430, 0.0%\n",
      "Model F1 >= Human F1 (Dialogs): 0 / 490, 0.0%\n",
      "=======================\n",
      "51 global_step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 11:39:39 - INFO - modeling -   Weights of AlbertForRetrieverOnlyPositivePassage not initialized from pretrained model: ['passage_encoder.embeddings.word_embeddings.weight', 'passage_encoder.embeddings.position_embeddings.weight', 'passage_encoder.embeddings.token_type_embeddings.weight', 'passage_encoder.embeddings.LayerNorm.weight', 'passage_encoder.embeddings.LayerNorm.bias', 'passage_encoder.encoder.embedding_hidden_mapping_in.weight', 'passage_encoder.encoder.embedding_hidden_mapping_in.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'passage_encoder.pooler.weight', 'passage_encoder.pooler.bias', 'passage_proj.weight', 'passage_proj.bias']\n",
      "05/17/2020 11:39:39 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/reader/config.json\n",
      "05/17/2020 11:39:39 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_qa_labels\": 2,\n",
      "  \"num_retrieval_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_loss_factor\": 1.0,\n",
      "  \"retrieval_loss_factor\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/17/2020 11:39:39 - INFO - transformers.modeling_utils -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-51/reader/pytorch_model.bin\n",
      "05/17/2020 11:39:43 - INFO - __main__ -   ***** Running evaluation 51 *****\n",
      "05/17/2020 11:39:43 - INFO - __main__ -     Num examples = 50\n",
      "05/17/2020 11:39:43 - INFO - __main__ -     Batch size = 2\n",
      "Evaluating: 100%|██████████| 25/25 [00:22<00:00,  1.57it/s]\n",
      "05/17/2020 11:40:07 - INFO - __main__ -     Evaluation done in total 23.185786 secs (0.463716 sec per example)\n",
      "05/17/2020 11:40:07 - INFO - utils -   Writing predictions to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/instance_predictions_51.json\n",
      "05/17/2020 11:40:07 - INFO - utils -   Writing nbest to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/instance_nbest_predictions_51.json\n",
      "05/17/2020 11:40:08 - INFO - utils -   Writing final predictions to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/final_predictions_51.json\n",
      "05/17/2020 11:40:08 - INFO - __main__ -   Results: {'unfiltered_f1_20': 0.09099137483630212, 'f1_20': 0.09099137483630211, 'HEQ_20': 0.0, 'DHEQ_20': 0.0, 'yes/no_20': 1.1370262390670554, 'followup_20': 0.7288629737609329, 'unanswerable_acc_20': 0.0, 'rerank_mrr_20': 0.056666666666666664, 'rerank_recall_20': 0.08, 'retriever_mrr_20': 0.024, 'retriever_recall_20': 0.08, 'unfiltered_f1_40': 0.061993720125818004, 'f1_40': 0.061993720125818004, 'HEQ_40': 0.0, 'DHEQ_40': 0.0, 'yes/no_40': 1.1370262390670554, 'followup_40': 0.7288629737609329, 'unanswerable_acc_40': 0.0, 'rerank_mrr_40': 0.06, 'rerank_recall_40': 0.08, 'retriever_mrr_40': 0.023, 'retriever_recall_40': 0.08, 'unfiltered_f1_51': 0.0684320097273729, 'f1_51': 0.0684320097273729, 'HEQ_51': 0.0, 'DHEQ_51': 0.0, 'yes/no_51': 1.1370262390670554, 'followup_51': 0.7288629737609329, 'unanswerable_acc_51': 0.0, 'rerank_mrr_51': 0.06, 'rerank_recall_51': 0.08, 'retriever_mrr_51': 0.02233333333333333, 'retriever_recall_51': 0.08}\n",
      "05/17/2020 11:40:08 - INFO - __main__ -   best metrics: {'unfiltered_f1': 0.09099137483630212, 'f1': 0.09099137483630211, 'HEQ': 0.0, 'DHEQ': 0.0, 'yes/no': 1.1370262390670554, 'followup': 0.7288629737609329, 'unanswerable_acc': 0.0, 'rerank_mrr': 0.056666666666666664, 'rerank_recall': 0.08, 'retriever_mrr': 0.024, 'retriever_recall': 0.08, 'global_step': '20'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall F1: 0.1\n",
      "Yes/No Accuracy : 1.1\n",
      "Followup Accuracy : 0.7\n",
      "Unfiltered F1 (3430 questions): 0.1\n",
      "Accuracy On Unanswerable Questions: 0.0 %% (602 questions)\n",
      "Human F1: 100.0\n",
      "Model F1 >= Human F1 (Questions): 0 / 3430, 0.0%\n",
      "Model F1 >= Human F1 (Dialogs): 0 / 490, 0.0%\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "# Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory\n",
    "\n",
    "results = {}\n",
    "max_f1 = 0.0\n",
    "best_metrics = {}\n",
    "if args.do_eval and args.local_rank in [-1, 0]:\n",
    "    retriever_tokenizer = retriever_tokenizer_class.from_pretrained(\n",
    "        args.retriever_tokenizer_dir, do_lower_case=args.do_lower_case)\n",
    "    reader_tokenizer = reader_tokenizer_class.from_pretrained(\n",
    "        args.reader_tokenizer_dir, do_lower_case=args.do_lower_case)\n",
    "    tb_writer = SummaryWriter(os.path.join(args.output_dir, 'logs'))\n",
    "    checkpoints = [args.output_dir]\n",
    "    if args.eval_all_checkpoints:\n",
    "        checkpoints = sorted(list(os.path.dirname(os.path.dirname(c)) for c in\n",
    "                                      glob.glob(args.output_dir + '/*/retriever/' + WEIGHTS_NAME, recursive=False)))\n",
    "#         logging.getLogger(\"transformers.modeling_utils\").setLevel(\n",
    "#             logging.WARN)  # Reduce model loading logs\n",
    "\n",
    "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "\n",
    "    for checkpoint in checkpoints:\n",
    "        # Reload the model\n",
    "        global_step = checkpoint.split(\n",
    "            '-')[-1] if len(checkpoint) > 1 else \"\"\n",
    "        print(global_step, 'global_step')\n",
    "        model = Pipeline()\n",
    "        model.retriever = retriever_model_class.from_pretrained(\n",
    "            os.path.join(checkpoint, 'retriever'), force_download=True)\n",
    "        model.retriever.passage_encoder = None\n",
    "        model.retriever.passage_proj = None\n",
    "        model.reader = reader_model_class.from_pretrained(\n",
    "            os.path.join(checkpoint, 'reader'), force_download=True)\n",
    "        model.to(args.device)\n",
    "\n",
    "        # Evaluate\n",
    "        result = evaluate(args, model, retriever_tokenizer,\n",
    "                          reader_tokenizer, prefix=global_step)\n",
    "        if result['f1'] > max_f1:\n",
    "            max_f1 = result['f1']\n",
    "            best_metrics = copy(result)\n",
    "            best_metrics['global_step'] = global_step\n",
    "\n",
    "        for key, value in result.items():\n",
    "            tb_writer.add_scalar(\n",
    "                'eval_{}'.format(key), value, global_step)\n",
    "\n",
    "        result = dict((k + ('_{}'.format(global_step) if global_step else ''), v)\n",
    "                      for k, v in result.items())\n",
    "        results.update(result)\n",
    "\n",
    "    best_metrics_file = os.path.join(\n",
    "        args.output_dir, 'predictions', 'best_metrics.json')\n",
    "    with open(best_metrics_file, 'w') as fout:\n",
    "        json.dump(best_metrics, fout)\n",
    "\n",
    "    all_results_file = os.path.join(\n",
    "        args.output_dir, 'predictions', 'all_results.json')\n",
    "    with open(all_results_file, 'w') as fout:\n",
    "        json.dump(results, fout)\n",
    "\n",
    "    logger.info(\"Results: {}\".format(results))\n",
    "    logger.info(\"best metrics: {}\".format(best_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T15:40:44.767673Z",
     "start_time": "2020-05-17T15:40:08.954245Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/17/2020 11:40:08 - INFO - __main__ -   Test the best checkpoint: /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20\n",
      "05/17/2020 11:40:08 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/retriever/config.json\n",
      "05/17/2020 11:40:08 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"proj_size\": 128,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "05/17/2020 11:40:08 - INFO - modeling -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/retriever/pytorch_model.bin\n",
      "05/17/2020 11:40:09 - INFO - modeling -   Weights of AlbertForRetrieverOnlyPositivePassage not initialized from pretrained model: ['passage_encoder.embeddings.word_embeddings.weight', 'passage_encoder.embeddings.position_embeddings.weight', 'passage_encoder.embeddings.token_type_embeddings.weight', 'passage_encoder.embeddings.LayerNorm.weight', 'passage_encoder.embeddings.LayerNorm.bias', 'passage_encoder.encoder.embedding_hidden_mapping_in.weight', 'passage_encoder.encoder.embedding_hidden_mapping_in.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'passage_encoder.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'passage_encoder.pooler.weight', 'passage_encoder.pooler.bias', 'passage_proj.weight', 'passage_proj.bias']\n",
      "05/17/2020 11:40:09 - INFO - transformers.configuration_utils -   loading configuration file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/reader/config.json\n",
      "05/17/2020 11:40:09 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_qa_labels\": 2,\n",
      "  \"num_retrieval_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_loss_factor\": 1.0,\n",
      "  \"retrieval_loss_factor\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/17/2020 11:40:09 - INFO - transformers.modeling_utils -   loading weights file /mnt/scratch/chenqu/orconvqa_output/release_test/checkpoint-20/reader/pytorch_model.bin\n",
      "05/17/2020 11:40:14 - INFO - __main__ -   ***** Running evaluation test *****\n",
      "05/17/2020 11:40:14 - INFO - __main__ -     Num examples = 50\n",
      "05/17/2020 11:40:14 - INFO - __main__ -     Batch size = 2\n",
      "Evaluating: 100%|██████████| 25/25 [00:18<00:00,  1.47it/s]\n",
      "05/17/2020 11:40:34 - INFO - __main__ -     Evaluation done in total 19.589293 secs (0.391786 sec per example)\n",
      "05/17/2020 11:40:34 - INFO - utils -   Writing predictions to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/instance_predictions_test.json\n",
      "05/17/2020 11:40:34 - INFO - utils -   Writing nbest to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/instance_nbest_predictions_test.json\n",
      "05/17/2020 11:40:36 - INFO - utils -   Writing final predictions to: /mnt/scratch/chenqu/orconvqa_output/release_test/predictions/final_predictions_test.json\n",
      "05/17/2020 11:40:44 - INFO - __main__ -   Test Result: {'unfiltered_f1': 0.06272970514040713, 'f1': 0.05094254726341879, 'HEQ': 0.017979144192736426, 'DHEQ': 0.0, 'yes/no': 0.5393743257820928, 'followup': 0.30564545127651926, 'unanswerable_acc': 0.0, 'rerank_mrr': 0.16, 'rerank_recall': 0.14, 'retriever_mrr': 0.12666666666666665, 'retriever_recall': 0.14}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Overall F1: 0.1\n",
      "Yes/No Accuracy : 0.5\n",
      "Followup Accuracy : 0.3\n",
      "Unfiltered F1 (5571 questions): 0.1\n",
      "Accuracy On Unanswerable Questions: 0.0 %% (1150 questions)\n",
      "Human F1: 80.8\n",
      "Model F1 >= Human F1 (Questions): 1 / 5562, 0.0%\n",
      "Model F1 >= Human F1 (Dialogs): 0 / 771, 0.0%\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "if args.do_test and args.local_rank in [-1, 0]:    \n",
    "    if args.do_eval:\n",
    "        best_global_step = best_metrics['global_step'] \n",
    "    else:\n",
    "        best_global_step = args.best_global_step\n",
    "        retriever_tokenizer = retriever_tokenizer_class.from_pretrained(\n",
    "            args.retriever_tokenizer_dir, do_lower_case=args.do_lower_case)\n",
    "        reader_tokenizer = reader_tokenizer_class.from_pretrained(\n",
    "            args.reader_tokenizer_dir, do_lower_case=args.do_lower_case)\n",
    "    best_checkpoint = os.path.join(\n",
    "        args.output_dir, 'checkpoint-{}'.format(best_global_step))\n",
    "    logger.info(\"Test the best checkpoint: %s\", best_checkpoint)\n",
    "\n",
    "    model = Pipeline()\n",
    "    model.retriever = retriever_model_class.from_pretrained(\n",
    "        os.path.join(best_checkpoint, 'retriever'), force_download=True)\n",
    "    model.retriever.passage_encoder = None\n",
    "    model.retriever.passage_proj = None\n",
    "    model.reader = reader_model_class.from_pretrained(\n",
    "        os.path.join(best_checkpoint, 'reader'), force_download=True)\n",
    "    model.to(args.device)\n",
    "\n",
    "    # Evaluate\n",
    "    result = evaluate(args, model, retriever_tokenizer,\n",
    "                      reader_tokenizer, prefix='test')\n",
    "\n",
    "    test_metrics_file = os.path.join(\n",
    "        args.output_dir, 'predictions', 'test_metrics.json')\n",
    "    with open(test_metrics_file, 'w') as fout:\n",
    "        json.dump(result, fout)\n",
    "\n",
    "    logger.info(\"Test Result: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
